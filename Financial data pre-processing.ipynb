{"nbformat": 4, "cells": [{"metadata": {"collapsed": false}, "source": "# Initialise azure machine learning workspace\nfrom azureml import Workspace\nws = Workspace()\n\n# Loads datasets from workspace\nindex_master_ds = ws.datasets['Index_Master.csv']\nindex_ds = ws.datasets['Index.csv']\nequity_ds = ws.datasets['Equity.csv']\n\n# Cast to dataframes\nindex_meta = index_master_ds.to_dataframe()\nindex_df = index_ds.to_dataframe()\nequity_df = equity_ds.to_dataframe()", "cell_type": "code", "outputs": [], "execution_count": 14}, {"metadata": {"collapsed": true}, "source": "aapl_ds = ws.datasets['AAPL_closing.csv']", "cell_type": "code", "outputs": [], "execution_count": 16}, {"metadata": {"collapsed": false}, "source": "print(type(index_ds))\nprint(type(aapl_ds))", "cell_type": "code", "outputs": [{"output_type": "stream", "text": "<class 'azureml.SourceDataset'>\n<class 'azureml.SourceDataset'>\n", "name": "stdout"}], "execution_count": 18}, {"metadata": {"collapsed": false}, "source": "\n\n#aapl = aapl_ds.to_dataframe()\nindex = index_ds.to_dataframe()\nprint(dir(aapl_ds))\nprint()\nprint(dir(index_ds))", "cell_type": "code", "outputs": [{"output_type": "stream", "text": "['Location', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_metadata', '_metadata_repr', '_to_dataframe', '_update_from_dataframe', '_update_from_raw_data', '_upload_and_refresh', 'batch', 'category', 'client_version', 'contents_url', 'created_date', 'created_date_ticks', 'culture', 'data_type_id', 'dataset_id', 'description', 'download_location', 'experiment_id', 'family_id', 'is_deprecated', 'is_example', 'is_latest', 'name', 'open', 'owner', 'promoted_from', 'read_as_binary', 'read_as_text', 'resource_upload_id', 'schema_end_point', 'schema_status', 'service_version', 'size', 'source_origin', 'update_from_dataframe', 'update_from_raw_data', 'uploaded_from_filename', 'visualize_end_point', 'workspace']\n\n['Location', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_metadata', '_metadata_repr', '_to_dataframe', '_update_from_dataframe', '_update_from_raw_data', '_upload_and_refresh', 'batch', 'category', 'client_version', 'contents_url', 'created_date', 'created_date_ticks', 'culture', 'data_type_id', 'dataset_id', 'description', 'download_location', 'experiment_id', 'family_id', 'is_deprecated', 'is_example', 'is_latest', 'name', 'open', 'owner', 'promoted_from', 'read_as_binary', 'read_as_text', 'resource_upload_id', 'schema_end_point', 'schema_status', 'service_version', 'size', 'source_origin', 'to_dataframe', 'update_from_dataframe', 'update_from_raw_data', 'uploaded_from_filename', 'visualize_end_point', 'workspace']\n", "name": "stdout"}], "execution_count": 26}, {"metadata": {}, "source": "## Pre-processing finanical data\n1. Fill the missing stock prices (i.e. Saturdays/Sundays)\n2. Compute log returns\n3. Pick out outliers, fill them back in with interpolation\n\nThe suite of main functions operates on a dataframe of one ticker. Use the getTicker() function to preprocess the main dataframe into a subset of one ticker", "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "source": "", "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"collapsed": false}, "source": "import numpy as np\nimport pandas as pd\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom scipy.stats import norm\n\ndef getTicker(df, ticker):\n    return df[df['Ticker'] == ticker]\n\ndef fillMissingData(ticker_df):\n    # parse date string to date objects\n    ticker_dates = pd.to_datetime(ticker_df['Date'], format='%Y-%m-%d').tolist()\n    ticker_price = ticker_df['Close'].tolist()\n    \n    for t1 in ticker_dates[0:-1]:\n        \n        # update the variables every iteration to make sure it they are consistent\n        t1_i = ticker_dates.index(t1)\n        t2 = ticker_dates[t1_i + 1]\n        day_diff = (t2 - t1).days\n        \n        if day_diff > 1:\n            for i in range(day_diff-1):\n                # inserts the interpolated price from the large to small (in case of multiple days gap)\n                ticker_dates.insert(t1_i+1, t1 + timedelta(days=day_diff-i-1))\n                ticker_price.insert(t1_i+1, ticker_price[t1_i] + (ticker_price[t1_i + 1] - ticker_price[t1_i]) * (day_diff-i-1) / day_diff)\n    \n    df = pd.DataFrame({\n            'Date': ticker_dates,\n            'Close': ticker_price\n        })\n    return df\n\ndef getLogReturn(ticker_df, tau):\n    ticker_df = ticker_df.as_matrix()\n    lr = np.log(ticker_df[tau:]/ticker_df[0:-tau])\n    return lr\n\ndef findOutliers(lr):\n    mu, sigma = norm.fit(lr)\n    outliers = np.logical_or(lr < mu-3*sigma, lr > mu+3*sigma)\n    return [i for i in range(len(outliers)) if outliers[i] == True]\n\n# assumes that outliers do not sit next to each other (to make my life easier)\ndef removeOutliers(lr, outliers_index):\n    outliers_index = np.array(outliers_index)\n\n    slid_forth = outliers_index - 1\n    slid_back = outliers_index + 1\n\n    lr[outliers_index] = (lr[slid_forth] + lr[slid_back] )/2\n    return lr", "cell_type": "code", "outputs": [], "execution_count": 4}, {"metadata": {}, "source": "# Usage demo", "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "source": "ticker = 'AAPL US Equity'\ntau = 1\ndf = equity_df\n\nticker_df = getTicker(df, ticker)\nticker_df = fillMissingData(ticker_df)\nlr = getLogReturn(ticker_df['Close'], tau)\noutliers = findOutliers(lr)\nlr = removeOutliers(lr, outliers)\npd.DataFrame({\n    'timestamp': ticker_df['Date'][:-1],\n    'price': lr\n})\nunix_timestamp = ticker_df['Date'][:-1].astype(np.int64) // 10**9\nunix_timestamp", "cell_type": "code", "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 27, "data": {"text/plain": "0       1167782400\n1       1167868800\n2       1167955200\n3       1168041600\n4       1168128000\n5       1168214400\n6       1168300800\n7       1168387200\n8       1168473600\n9       1168560000\n10      1168646400\n11      1168732800\n12      1168819200\n13      1168905600\n14      1168992000\n15      1169078400\n16      1169164800\n17      1169251200\n18      1169337600\n19      1169424000\n20      1169510400\n21      1169596800\n22      1169683200\n23      1169769600\n24      1169856000\n25      1169942400\n26      1170028800\n27      1170115200\n28      1170201600\n29      1170288000\n           ...    \n3687    1486339200\n3688    1486425600\n3689    1486512000\n3690    1486598400\n3691    1486684800\n3692    1486771200\n3693    1486857600\n3694    1486944000\n3695    1487030400\n3696    1487116800\n3697    1487203200\n3698    1487289600\n3699    1487376000\n3700    1487462400\n3701    1487548800\n3702    1487635200\n3703    1487721600\n3704    1487808000\n3705    1487894400\n3706    1487980800\n3707    1488067200\n3708    1488153600\n3709    1488240000\n3710    1488326400\n3711    1488412800\n3712    1488499200\n3713    1488585600\n3714    1488672000\n3715    1488758400\n3716    1488844800\nName: Date, dtype: int64"}}], "execution_count": 27}, {"metadata": {}, "source": "Nothing to see down there", "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "source": "# Just a random try stuff out box\n\nimport pandas as pd\nfrom datetime import datetime\nfrom datetime import date\nfrom datetime import timedelta\n\nd = date(5, 12, 17)\nd = datetime.strptime('01-12-15', '%d-%m-%y')\n\ndate = pd.DataFrame(['28-05-07', '29-05-07'])\n\ndates = pd.to_datetime(date[0], format='%d-%m-%y')\ndates[0] + timedelta(days=1)\n\nticker_df = getTicker(index_df, 'DAX Index')\nticker_date = ticker_df['Date']\npd.to_datetime(ticker_date, format='%Y-%m-%d')\n\n1/3", "cell_type": "code", "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 5, "data": {"text/plain": "0.3333333333333333"}}], "execution_count": 5}], "metadata": {"language_info": {"nbconvert_exporter": "python", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.4.5", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "nbformat_minor": 0}